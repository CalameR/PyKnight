{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn import cluster, datasets, mixture\n",
    "#from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import cycle, islice\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"\\\\Users\\\\pierreguilleminet\\\\Google Drive\\\\IA\\\\ML EY\"\n",
    "if(path[-1] != \"\\\\\"):\n",
    "    path += \"\\\\\"\n",
    "\n",
    "csv_file = \"Price.csv\"\n",
    "print(path + csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(csv_file, sep='\\t')\n",
    "#data = pd.read_csv(path + csv_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(list(data.columns.values))\n",
    "print(data[\"Price_outlier\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_to_keep = ['Strike', 'Rate', 'Vol', 'Maturity']\n",
    "input_to_drop = []\n",
    "\n",
    "for x in data.columns.values:\n",
    "    if x not in input_to_keep:\n",
    "        input_to_drop.append(x)\n",
    "        \n",
    "X = data.drop(labels=input_to_drop, axis=1)\n",
    "y = data[\"Price\"]\n",
    "\n",
    "print(list(X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = 1 # to train the RNN\n",
    "test_set = 1-train_set # to test the calibration\n",
    "validation_set = 0 # to test several sets of hyperparameters\n",
    "final_test_set = 0 # to test the best calibration \n",
    "\n",
    "probs = np.random.rand(len(data))\n",
    "training_mask = probs < train_set\n",
    "test_mask = (probs>=train_set) & (probs < train_set+test_set)\n",
    "validation_mask = (probs>=train_set+test_set) & (probs < train_set+test_set+validation_set)\n",
    "final_test_mask = probs >= train_set+test_set+validation_set\n",
    "\n",
    "X_train = X[training_mask]\n",
    "X_test = X[test_mask]\n",
    "X_validation = X[validation_mask]\n",
    "X_final_test = X[final_test_mask]\n",
    "\n",
    "y_train = y[training_mask]\n",
    "y_test = y[test_mask]\n",
    "y_validation = y[validation_mask]\n",
    "y_final_test = y[final_test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set:475200 (1.0)\n",
      "test_set:0 (0.0)\n",
      "validation_set:0 (0.0)\n",
      "final_test_set:0 (0.0)\n",
      "Check: True\n"
     ]
    }
   ],
   "source": [
    "print(\"train_set:\" + str(len(X_train)) + \" (\" + str(round(len(X_train) / len(data), 2)) + \")\")\n",
    "print(\"test_set:\" + str(len(X_test)) + \" (\" + str(round(len(X_test) / len(data), 2)) + \")\")\n",
    "print(\"validation_set:\" + str(len(X_validation)) + \" (\" + str(round(len(X_validation) / len(data), 2)) + \")\")\n",
    "print(\"final_test_set:\" + str(len(X_final_test)) + \" (\" + str(round(len(X_final_test) / len(data), 2)) + \")\")\n",
    "print(\"Check: \" + str(len(data) == len(X_train) + len(X_test)+len(X_validation)+len(X_final_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting RNN parameters\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
    "\n",
    "params_default = {\n",
    "    \"hidden_layer_sizes\" : (1, ), \n",
    "    \"activation\" : \"relu\", \n",
    "    \"solver\" : \"adam\", \n",
    "    \"alpha\" : 0.0001, \n",
    "    \"batch_size\" : \"auto\", \n",
    "    \"learning_rate\" : \"constant\", \n",
    "    \"learning_rate_init\" : 0.001, \n",
    "    \"power_t\" : 0.5, \n",
    "    \"max_iter\" : 200, \n",
    "    \"shuffle\" : True, \n",
    "    \"random_state\" : None, \n",
    "    \"tol\" : 0.0001, \n",
    "    \"verbose\" : False, \n",
    "    \"warm_start\" : False, \n",
    "    \"momentum\" : 0.9, \n",
    "    \"nesterovs_momentum\" : True, \n",
    "    \"early_stopping\" : False, \n",
    "    \"validation_fraction\" : 0.1, \n",
    "    \"beta_1\" : 0.9, \n",
    "    \"beta_2\" : 0.999, \n",
    "    \"epsilon\" : 1e-08\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (100, 100, 100, 100), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'batch_size': 'auto', 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'power_t': 0.5, 'max_iter': 200, 'shuffle': True, 'random_state': None, 'tol': 0.0001, 'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True, 'early_stopping': False, 'validation_fraction': 0.1, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "algo_params = {\n",
    "    \"hidden_layer_sizes\" : (100, 100, 100, 100),\n",
    "    \"batch_size\" : \"auto\",\n",
    "}\n",
    "\n",
    "params = params_default.copy()\n",
    "params.update(algo_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = MLPRegressor(\n",
    "    hidden_layer_sizes =  params[\"hidden_layer_sizes\"], \n",
    "    activation =  params[\"activation\"],\n",
    "    solver =  params[\"solver\"],\n",
    "    alpha =  params[\"alpha\"], \n",
    "    batch_size =  params[\"batch_size\"],\n",
    "    learning_rate =  params[\"learning_rate\"], \n",
    "    learning_rate_init =  params[\"learning_rate_init\"], \n",
    "    power_t =  params[\"power_t\"], \n",
    "    max_iter =  params[\"max_iter\"], \n",
    "    shuffle =  params[\"shuffle\"], \n",
    "    random_state =  params[\"random_state\"], \n",
    "    tol =  params[\"tol\"], \n",
    "    verbose =  params[\"verbose\"], \n",
    "    warm_start =  params[\"warm_start\"], \n",
    "    momentum =  params[\"momentum\"], \n",
    "    nesterovs_momentum =  params[\"nesterovs_momentum\"], \n",
    "    early_stopping =  params[\"early_stopping\"], \n",
    "    validation_fraction =  params[\"validation_fraction\"], \n",
    "    beta_1 =  params[\"beta_1\"], \n",
    "    beta_2 =  params[\"beta_2\"], \n",
    "    epsilon =  params[\"epsilon\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "if train_set > 0: \n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    #y_train = StandardScaler().fit_transform(y_train)\n",
    "if test_set > 0: \n",
    "    test_set = StandardScaler().fit_transform(test_set)\n",
    "    #y_test = StandardScaler().fit_transform(y_test)\n",
    "if validation_set > 0: \n",
    "    validation_set = StandardScaler().fit_transform(validation_set)\n",
    "    #y_validation = StandardScaler().fit_transform(y_validation)\n",
    "if final_test_set > 0: \n",
    "    final_test_set = StandardScaler().fit_transform(final_test_set)\n",
    "    #y_final_test = StandardScaler().fit_transform(y_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.fit(X_train,y_train)\n",
    "#rnn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_In_sample = rnn.predict(X_train)\n",
    "error_In = prediction_In_sample - y_train\n",
    "if test_set > 0:\n",
    "    prediction_Out_sample = rnn.predict(X_test)\n",
    "    error_Out = prediction_Out_sample - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.distplot(error_In, kde=False, color=\"blue\", hist = True, norm_hist=False)\n",
    "plt.title(\"Erreur In sample\")\n",
    "plt.show()\n",
    "\n",
    "if test_set > 0:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.distplot(error_Out, kde=False, color=\"blue\", hist = True, norm_hist=False)\n",
    "    plt.title(\"Erreur Out of sample\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"Prediction In Sample\"] = prediction_In_sample\n",
    "data[\"Error In sample\"] = error_In\n",
    "if test_set > 0:\n",
    "    data[\"Prediction Out Sample\"] = prediction_Out_sample\n",
    "    data[\"Error Out sample\"] = error_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"Prediction.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relative_error = []\n",
    "for i, x in enumerate(y):\n",
    "    if np.abs(x) > 0.000001:\n",
    "        relative_error.append(prediction[i] / y[i] - 1)\n",
    "#relative_error = prediction / y - 1\n",
    "#print(np.min(relative_error))\n",
    "print(np.mean(relative_error))\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.distplot(relative_error, kde=False, color=\"blue\", hist = True, norm_hist=False)\n",
    "plt.title(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = np.average(np.power(error,2))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_qty_min = 0.1\n",
    "data_qty_max = 1\n",
    "data_qty_nb = 20\n",
    "data_qty_step = (data_qty_max - data_qty_min)/(data_qty_nb-1)\n",
    "\n",
    "layers_min = 1\n",
    "layers_max = 5\n",
    "layers_nb = 3\n",
    "layers_step = (layers_max - layers_min)/(layers_nb-1)\n",
    "\n",
    "neurones_min = 1\n",
    "neurones_max = 100\n",
    "neurones_nb = 3\n",
    "neurones_step = (neurones_max - neurones_min)/(neurones_nb-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mode = False\n",
    "if test_mode:\n",
    "    data_qty_min = 0.1\n",
    "    data_qty_max = 1\n",
    "    data_qty_nb = 2\n",
    "    data_qty_step = (data_qty_max - data_qty_min)/(data_qty_nb-1)\n",
    "\n",
    "    layers_min = 1\n",
    "    layers_max = 2\n",
    "    layers_nb = 2\n",
    "    layers_step = (layers_max - layers_min)/(layers_nb-1)\n",
    "\n",
    "    neurones_min = 1\n",
    "    neurones_max = 100\n",
    "    neurones_nb = 2\n",
    "    neurones_step = (neurones_max - neurones_min)/(neurones_nb-1)\n",
    "\n",
    "data_qty = np.arange(data_qty_min, data_qty_max+data_qty_step, data_qty_step)\n",
    "data_qty = [round(x, 2) for x in data_qty]\n",
    "layers = np.arange(layers_min, layers_max+layers_step, layers_step)\n",
    "layers = [int(x) for x in layers]\n",
    "neurones = np.arange(neurones_min, neurones_max+neurones_step, neurones_step)\n",
    "neurones = [int(x) for x in neurones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_layers_neurones(layer, neurone):\n",
    "    hidden_layer_sizes = (neurone, )\n",
    "    if layer == 1.0: return hidden_layer_sizes\n",
    "    elif layer > 1.0:\n",
    "        for i in range(layer-1):\n",
    "            hidden_layer_sizes += (neurone,)\n",
    "        return hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 50, 30, 20)]\n",
      "[(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "layers = [1, 2, 5]\n",
    "neurones = [1, 50, 100]\n",
    "\n",
    "layers_neurones = [[(100, 50, 30, 20)],\n",
    "                  [(1, 1)]]\n",
    "\n",
    "for x in layers_neurones:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 0.1 layer/neurones: 4/1 error: 32.3042105322\n",
      "Data: 0.15 layer/neurones: 4/1 error: 19.7477191767\n",
      "Data: 0.19 layer/neurones: 4/1 error: 25.2980536988\n",
      "Data: 0.24 layer/neurones: 4/1 error: 18.2534763087\n",
      "Data: 0.29 layer/neurones: 4/1 error: 18.0436074473\n",
      "Data: 0.34 layer/neurones: 4/1 error: 33.6019702528\n",
      "Data: 0.38 layer/neurones: 4/1 error: 11.2667202401\n",
      "Data: 0.43 layer/neurones: 4/1 error: 19.3395813777\n",
      "Data: 0.48 layer/neurones: 4/1 error: 8.67793398195\n",
      "Data: 0.53 layer/neurones: 4/1 error: 30.257952343\n",
      "Data: 0.57 layer/neurones: 4/1 error: 18.3350685357\n",
      "Data: 0.62 layer/neurones: 4/1 error: 18.5584110079\n",
      "Data: 0.67 layer/neurones: 4/1 error: 7.25976082063\n",
      "Data: 0.72 layer/neurones: 4/1 error: 7.58309771127\n",
      "Data: 0.76 layer/neurones: 4/1 error: 8.61052349683\n",
      "Data: 0.81 layer/neurones: 4/1 error: 11.3219175328\n",
      "Data: 0.86 layer/neurones: 4/1 error: 13.9562794838\n",
      "Data: 0.91 layer/neurones: 4/1 error: 12.5414879454\n",
      "Data: 0.95 layer/neurones: 4/1 error: 4.03708854445\n",
      "Data: 1.0 layer/neurones: 4/1 error: 7.31666749018\n"
     ]
    }
   ],
   "source": [
    "algo_params = {\n",
    "\"batch_size\" : \"auto\",\n",
    "}\n",
    "params = params_default.copy()\n",
    "params.update(algo_params)\n",
    "\n",
    "labels = [\"data_qty\", \"layers/neurones\", \"mse\"]\n",
    "prediction = []\n",
    "\n",
    "probs = np.random.rand(len(data))\n",
    "for data_prop in data_qty:\n",
    "    X_prop = probs < data_prop\n",
    "    X_data = X[X_prop]\n",
    "    y_data = y[X_prop]\n",
    "    X_data = StandardScaler().fit_transform(X_data)\n",
    "    for layer_neurone in layers_neurones:\n",
    "        algo_params = {\n",
    "        \"hidden_layer_sizes\" : layer_neurone[2] ,\n",
    "        }\n",
    "        params = params.copy()\n",
    "        params.update(algo_params)\n",
    "        rnn = MLPRegressor(\n",
    "            hidden_layer_sizes =  params[\"hidden_layer_sizes\"], \n",
    "            activation =  params[\"activation\"],\n",
    "            solver =  params[\"solver\"],\n",
    "            alpha =  params[\"alpha\"], \n",
    "            batch_size =  params[\"batch_size\"],\n",
    "            learning_rate =  params[\"learning_rate\"], \n",
    "            learning_rate_init =  params[\"learning_rate_init\"], \n",
    "            power_t =  params[\"power_t\"], \n",
    "            max_iter =  params[\"max_iter\"], \n",
    "            shuffle =  params[\"shuffle\"], \n",
    "            random_state =  params[\"random_state\"], \n",
    "            tol =  params[\"tol\"], \n",
    "            verbose =  params[\"verbose\"], \n",
    "            warm_start =  params[\"warm_start\"], \n",
    "            momentum =  params[\"momentum\"], \n",
    "            nesterovs_momentum =  params[\"nesterovs_momentum\"], \n",
    "            early_stopping =  params[\"early_stopping\"], \n",
    "            validation_fraction =  params[\"validation_fraction\"], \n",
    "            beta_1 =  params[\"beta_1\"], \n",
    "            beta_2 =  params[\"beta_2\"], \n",
    "            epsilon =  params[\"epsilon\"]\n",
    "        )\n",
    "        rnn.fit(X_data,y_data)\n",
    "        prediction_temp = rnn.predict(X_data) # prediction in sample\n",
    "        error = []\n",
    "        for i, y_temp in enumerate(y_data):\n",
    "            if np.abs(y_temp) > 0.000001:\n",
    "                error.append(prediction_temp[i] / y_temp - 1)\n",
    "        mse_temp = np.average(np.abs(error))\n",
    "        #mse_temp = np.average(np.power(prediction_temp - y_data,2))\n",
    "        #MSE_train = mean_squared_error(df_train[use_feature][n_steps:], pred_train[:, 0])\n",
    "        prediction.append([data_prop, str(layer_neurone[0])+\"/\"+str(layer_neurone[1]), mse_temp])\n",
    "        print(\"Data: \" + str(round(data_prop, 2)) + \" layer/neurones: \" + str(layer_neurone[0])+\"/\"+str(layer_neurone[1])\n",
    "             +\" error: \" + str(mse_temp))\n",
    "    \n",
    "output = pd.DataFrame(prediction, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"Output.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
